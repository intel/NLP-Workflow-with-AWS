{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff2793b0",
   "metadata": {},
   "source": [
    "Copyright (C) 2022 Intel Corporation\n",
    " \n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    " \n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    " \n",
    "Unless required by applicable law or agreed to in writing,\n",
    "software distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions\n",
    "and limitations under the License.\n",
    " \n",
    "\n",
    "SPDX-License-Identifier: Apache-2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90898431",
   "metadata": {},
   "source": [
    "# General Description\n",
    "\n",
    "Version: 1.0\n",
    "Date: Sep 15, 2022\n",
    "\n",
    "This notebook outlines the general usage of using Intel's CPU, Intel optimized PyTorch, Intel Extension for PyTorch on Amazon EKS platform. \n",
    "\n",
    "A BERT model is fine-tuned using HuggingFace framework and with IPEX optimization. As a result, a FP32 BERT model is generated and stored into a Amazon Elastic File System.\n",
    "\n",
    "Users are free to based on any part of the codes and customize those to suit their purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50776f4b",
   "metadata": {},
   "source": [
    "# Prerequisite\n",
    "\n",
    "- It is expected that there is already a EKS cluster hosted and setup properly. \n",
    "   The EKS cluster should have:\n",
    "    1. Kubeflow installed\n",
    "    2. Associated related AWS credentials (i.e. you are able to use 'kubectl' to create/delete training jobs)\n",
    "    3. A Elastic File System (EFS) that is accesible(read and write) by the cluster nodes\n",
    "    4.  2 nodes or above (optional but recommended)\n",
    "   \n",
    "   Please contact your EKS administrator to obtain the necessary information.\n",
    "   \n",
    "   You may also refer to the following webpage to create a new EKS cluster and install the kubeflow.\n",
    "   - https://docs.aws.amazon.com/deep-learning-containers/latest/devguide/deep-learning-containers-eks-setup.html\n",
    "   - https://www.eksworkshop.com/advanced/420_kubeflow/install/\n",
    "   \n",
    "- Setup the Amazon credential credential (e.g.: aws configure) \n",
    "   1. in the container\n",
    "   2. the docker host \n",
    "\n",
    "- Set the notebook kernel to use 'Python 3 (ipykernel)'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f3a628",
   "metadata": {},
   "source": [
    "# Step 1: Build a custom docker image for training\n",
    "\n",
    "    1. Copy the content of the \"../src/eks_training_container\" and paste those outside the docker container. \n",
    "    2. Modify the AWS credential of the build_and_push.sh \n",
    "       Pay attention to the region, account number, algorithm_name and the firewall issue\n",
    "    3. Run build_and_push.sh to build the custom docker image for training.\n",
    "\n",
    "Note: \n",
    "- Users may change the content of the \"train.py\" to adjust the nature of the training task/use different BERT models/change the behavior of Intel Neural Compressor\n",
    "- For this reference design, it is assumed that the EFS mounted path is /data and accessible by the cluster nodes. The trained model will be stored under the /data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3028071f",
   "metadata": {},
   "source": [
    "# Step 2a: Set kubectl to the target cluster\n",
    "\n",
    "We will first use the following command to set `kubectl`.\n",
    "\n",
    "Please modify and run the follwoing command to set the proper cluster target for 'kubectl'\n",
    "<region> is the Amaozn EKS Region\n",
    "<cluster-name> is the cluster name shown in the Amazon Elastic Kubernetes Service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ee3616",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "aws eks --region us-west-2 update-kubeconfig --name eks-clustereks120"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b982ce",
   "metadata": {},
   "source": [
    "# Step 2b: Get the details of the nodes\n",
    "\n",
    "The following command will list the nodes we are able to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a6bc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh \n",
    "kubectl get nodes -o wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83813a2",
   "metadata": {},
   "source": [
    "# Step 2c: Label the nodes\n",
    "\n",
    "In order to achieve efficient distributed training. It is necessary to label the kubernate nodes properly. When we perform the training, we will provide a config file (in .yaml format) and distribute the jobs to the nodes by using the label. Please based on the above output and run the following command to label the nodes.\n",
    "\n",
    "You may run the following command several times to label the node manually. Please modify the content in the '<>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41df250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "kubectl label nodes <name-of-the-node> nodename=<node1> --overwrite "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586d5f42",
   "metadata": {},
   "source": [
    "# Step 3: Assign the training job by modifying the config file (.yaml)\n",
    "\n",
    "The training job is created by calling 'kubectl' on the config file. By modifying the config file, we can assign the computational resources (i.e. the nodes and EFS) for the training job.\n",
    "\n",
    "Please modify the distributed_training.yaml to specify the resources, especially the following items:\n",
    "1. name        -- change to a name that suits the task. This will be used when checking the logs/pods execution.\n",
    "2. replicas    -- it is recommended to set 1 for the Master and n-1 (n is the total number of nodes) for worker \n",
    "3. image       -- it should be the one you built in step 1\n",
    "4. mountPath   -- the path where the fine-tuned model is stored\n",
    "5. claimName   -- the name of the EFS storage. May need to ask EKS administrator regarding to the details\n",
    "6. cpu         -- it is recommended to set the value equals to (n/2) + 1, where n is the number of vCPU of the instance. This \n",
    "                  will be a hint to inform Kubernate to distribute the training job evenly to the computational nodes. \n",
    "                  Otherwise the job may stay in 1 node and result in poor performance (i.e. not the expected distributed \n",
    "                  training)\n",
    "7. memory      -- you may check the type of the instance and request depends on the task nature\n",
    "8. values      -- use the labels set in Step 2c. This tells K8S to use specific nodes for training and assign correct affinity.\n",
    "\n",
    "Note: If there is unexpected distributed training performance, users may use the following command to check if the training job is distributed into different nodes.\n",
    "\n",
    "`kubectl get pods -o wide`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f9a3ad",
   "metadata": {},
   "source": [
    "# Step 4: Start the training\n",
    "\n",
    "After having the pod specification defined in the previous step, users may start the training job on the EKS cluster by calling the command in the next block cell.\n",
    "\n",
    "Users may use the following command to check the execution status/logs of the training job\n",
    "1. kubectl logs -f <name-of-the-job/pod>\n",
    "2. kubectl describe pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0535a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "kubectl create -f ../src/eks_training_container/distributed_training.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb82ee7",
   "metadata": {},
   "source": [
    "# Step 5: Clean up\n",
    "\n",
    "After the job is completed, the fine-tuned FP32 model should be stored in the EFS mountPath (in this case, /data). Users may wish to release the resources by calling the following two commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cf54e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "kubectl delete <pytorchjobs.kubeflow.org/the-job-name> #e.g.: pytorchjobs.kubeflow.org/xxxxxxxxxxxxx\n",
    "kubectl delete pod --all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
