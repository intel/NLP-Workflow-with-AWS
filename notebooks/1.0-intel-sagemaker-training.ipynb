{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "316bc07c",
   "metadata": {},
   "source": [
    "Copyright (C) 2022 Intel Corporation\n",
    " \n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    " \n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    " \n",
    "Unless required by applicable law or agreed to in writing,\n",
    "software distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions\n",
    "and limitations under the License.\n",
    " \n",
    "\n",
    "SPDX-License-Identifier: Apache-2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90898431",
   "metadata": {},
   "source": [
    "# General Description\n",
    "\n",
    "Version: 1.1 Date: Oct 28, 2022\n",
    "\n",
    "This notebook outlines the general usage of cloud training platform using Intel's CPU, Intel optimized TensorFlow, Intel Neural Compressor on Amazon SageMaker platform. A BERT model is fine-tuned using HuggingFace framework and a quantized (INT8) BERT model is generated as a result.\n",
    "\n",
    "Users may wish to based on parts of the codes and customize those to suit their purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50776f4b",
   "metadata": {},
   "source": [
    "# Prerequisite\n",
    "\n",
    "1. Setup the Amazon AWS credential (e.g.: aws configure) in the \n",
    "    i. container \n",
    "    ii. docker host environment\n",
    "    \n",
    "2. Set the notebook kernel to use 'Python 3 (ipykernel)'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4601376e",
   "metadata": {},
   "source": [
    "# Step 0: Specify the AWS information (Optional)\n",
    "\n",
    "Users may wish to specify the AWS information in the ./config/config.yaml file to pre-fill the necessary information required for the workflow. Or users may also fill in the necessary fields when executing the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d81fa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('./config/sagemaker_config.yaml') as f:\n",
    "    config_dict = yaml.safe_load(f)\n",
    "    read_from_yaml = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f3a628",
   "metadata": {},
   "source": [
    "# Step 1: Build a custom docker image for training\n",
    "\n",
    "    1. Copy the content of the \"../src/sagemaker_training_container\" and paste those outside the docker container. \n",
    "    2. Modify the AWS credential of the build_and_push.sh \n",
    "       Pay attention to the region, account number, algorithm_name and the firewall issue \n",
    "    3. Run build_and_push.sh to build the custom docker image for training.\n",
    "\n",
    "Note: Users may change the content of the \"train.py\" to adjust the nature of the training task/use different BERT models/change the behavior of Intel Neural Compressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0feb5e",
   "metadata": {},
   "source": [
    "# Step 2: Run the training codes using SageMaker\n",
    "Users may wish to change the type of the cluster nodes and the number of the nodes for their training purposes. \n",
    "\n",
    "Please change the two variables 'target_instance_type' and 'num_of_nodes' to achieve this purpose.\n",
    "\n",
    "List of EC2 instances: https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-available-instance-types.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511f56ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sagemaker.tensorflow.estimator import TensorFlow\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "if read_from_yaml:\n",
    "    role = config_dict['role']\n",
    "    image_uri = config_dict['training_image_uri']\n",
    "else:\n",
    "    role = '' #e.g.: AmazonSageMaker-ExecutionRole-xxxxxxxxxxxxxx\n",
    "    image_uri = '' #e.g.: xxxxxxxxxxxxx.dkr.ecr.us-west-2.amazonaws.com/sagemaker-inteltf-huggingface-inc:latest\n",
    "    \n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n",
    "\n",
    "#Users may change the following two parameters to create a cluster they wish\n",
    "target_instance_type = 'ml.c5.18xlarge'\n",
    "num_of_nodes = 3\n",
    "\n",
    "#Training with Horovod: https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html#training-with-horovod\n",
    "tensorflow_estimator =  TensorFlow(entry_point='../src/sagemaker_training_container/dummy.py', \n",
    "                            instance_type=target_instance_type, #Just create a dummy python file to enable this API. In order to change the training behavior, users should change the train.py and rebuild the docker image by running the build_and_push.sh\n",
    "                            instance_count=num_of_nodes,\n",
    "                            image_uri = image_uri, #e.g.: xxxxxxxxxxxxx.dkr.ecr.us-west-2.amazonaws.com/sagemaker-inteltf-huggingface-inc:latest\n",
    "                            role=role,\n",
    "                            hyperparameters = {'epochs': 5,\n",
    "                                            'train_batch_size': 32,\n",
    "                                            'model_name':'bert-base-uncased'\n",
    "                                                },\n",
    "                            #script_mode=True,\n",
    "                            distribution = {\"mpi\": {\"enabled\": True} }\n",
    "                                   \n",
    "                        )\n",
    "tensorflow_estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6845c312",
   "metadata": {},
   "source": [
    "# Step 3: Convert the quantized model into SavedModel format\n",
    "\n",
    "- Download the S3 model artifact manually\n",
    "      Visit Amazon \"SageMaker\" website and click in the \"Training Jobs\". Find the training job that has the same name as above and download the S3 model artifact (model.tar.gz). Unzip the model.tar.gz and upload the ptq_model.pb under the same directory of this notebook for Post-Training Quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a062419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deployment using TensorFlowModel provided by SageMaker\n",
    "#Convert the quantized pb model into SavedModel format\n",
    "#import tensorflow as tf\n",
    "#tf.disable_v2_behavior()\n",
    "import tensorflow.compat.v1 as tf \n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "def convert_pb_to_savedmodel(pb_model_path, output_dir):\n",
    "    #Read pb model\n",
    "    graph_def = tf.compat.v1.GraphDef()\n",
    "    with open(pb_model_path, 'rb') as f:\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    #Save the BERT pb model into SavedModel\n",
    "    builder, sigs = tf.saved_model.builder.SavedModelBuilder(output_dir), {}\n",
    "    with tf.Session(graph=tf.Graph()) as sess:\n",
    "        tf.import_graph_def(graph_def, name=\"\")\n",
    "        g = tf.get_default_graph()\n",
    "        in1 = g.get_tensor_by_name('attention_mask:0')\n",
    "        in2 = g.get_tensor_by_name('input_ids:0')\n",
    "        in3 = g.get_tensor_by_name('token_type_ids:0')\n",
    "        out = g.get_tensor_by_name('Identity:0')\n",
    "        sigs[signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY] = \\\n",
    "            tf.saved_model.signature_def_utils.predict_signature_def(\n",
    "                {\"attention_mask\": in1, \"input_ids\": in2,  \"token_type_ids\": in3}, {\"Identity\": out})\n",
    "\n",
    "        builder.add_meta_graph_and_variables(sess,\n",
    "                                            [tag_constants.SERVING],\n",
    "                                            signature_def_map=sigs)\n",
    "        builder.save()\n",
    "    return\n",
    "\n",
    "#Retrieve the pb from the SageMaker Training Job\n",
    "pb_model_path = \"./ptq_model.pb\"\n",
    "savedmodel_output_dir = \"./ptq_model_savedmodel/saved_model/1/\"\n",
    "\n",
    "convert_pb_to_savedmodel(pb_model_path, savedmodel_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36749a89",
   "metadata": {},
   "source": [
    "# Step 4: Compress and zip the quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf339ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czf ./model.tar.gz ./ptq_model_savedmodel/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49900ba1",
   "metadata": {},
   "source": [
    "# Step 5: Upload the quantized model to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65db6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.session import Session\n",
    "\n",
    "model_data = Session().upload_data(path=\"./model.tar.gz\", key_prefix=\"model\")\n",
    "print(\"model uploaded to: {}\".format(model_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
